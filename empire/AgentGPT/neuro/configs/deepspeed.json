{
  "train_batch_size": 128,
  "gradient_accumulation_steps": 2,
  "bf16": {"enabled": true},
  "zero_optimization": {"stage": 2, "contiguous_gradients": true},
  "wall_clock_breakdown": false,
  "optimizer": {"type": "AdamW", "params": {"lr": 0.0002, "betas": [0.9, 0.95], "eps": 1e-8, "weight_decay": 0.05}},
  "scheduler": {"type": "CosineAnnealing", "params": {"warmup_min_lr": 1e-5, "warmup_max_lr": 0.0002, "warmup_num_steps": 2000}}
}